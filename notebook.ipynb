{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Predicting Allstate insurance claim severity\n## Exploratory Data Analysis\nThis notebook contains the exploratory data analysis performed on the training dataset provided by Allstate to predict insurance claim severity, analysis is performed on the following topics\n\n1. Training and testing dataset statistics\n2. missing values\n3. distribution of continuous features and transformation if necessary\n\nBased on the analysis of feature transformation, best possible feature is picked for preprocessing.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# loading required modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport math\n%matplotlib inline",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# load train and test dataset\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# printing train dataset information\ntrain.info()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# printing test dataset information\ntest.info()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train.columns[train.isnull().sum() > 0 ]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# setting pandas env variables to display max rows and columns\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows',1000)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# describing statistics of continuous variables\ntrain.describe()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# describing statistics of categorical variables\ntrain.describe(include = ['object'])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# sepearte the categorical and continous features\ncont_columns = []\ncat_columns = []\n\nfor i in train.columns:\n    if train[i].dtype == 'float':\n        cont_columns.append(i)\n    elif train[i].dtype == 'object':\n        cat_columns.append(i)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# log transform the label variable\ntrain['loss'] = np.log1p(train['loss'])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.pairplot(train[cont_columns], vars=['cont1','cont2','cont3','cont4','loss'], kind = 'scatter',diag_kind='kde')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.pairplot(train[cont_columns], vars=['cont5','cont6','cont7','cont8','loss'], kind = 'scatter',diag_kind='kde')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.pairplot(train[cont_columns], vars=['cont9','cont10','cont11','cont12','loss'], kind = 'scatter',diag_kind='kde')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.pairplot(train[cont_columns], vars=['cont13','cont14','loss'], kind = 'scatter',diag_kind='kde')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.pairplot(train[cont_columns], kind = 'scatter',diag_kind='kde')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(10,10))\nplt.hist(train.loss, bins=100)\nplt.title(\"histogram of target variable\")\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Compute the correlation matrix\ncorr = train[cont_columns].corr()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.set(style=\"white\")\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cont_columns.remove('loss')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's look at the probability plot of continuous variables",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.gridspec as gridspec\nfrom scipy import stats\n\nplt.figure(figsize=(15,25))\ngs = gridspec.GridSpec(7, 2)\nfor i, cn in enumerate(train[cont_columns].columns):\n    ax = plt.subplot(gs[i])\n    stats.probplot(train[cn], dist = stats.norm, plot = ax)\n    ax.set_xlabel('')\n    ax.set_title('Probplot of feature: cont' + str(i+1))\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's look at the skewness and plot them.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "skewness_list = []\nfor cn in train[cont_columns].columns:\n    skewness_list.append(stats.skew(train[cn]))\n\nplt.figure(figsize=(10,7))\nplt.plot(skewness_list, 'bo-')\nplt.xlabel(\"continous features\")\nplt.ylabel(\"skewness\")\nplt.title(\"plotting skewness of the continous features\")\nplt.xticks(range(15), range(1,15,1))\nplt.plot([(0.25) for i in range(0,14)], 'r--')\nplt.text(6, .1, 'threshold = 0.25')\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Except couple of features, all of them have skewness above 0.25, let's look at their distribution and experiment with different transformations.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "skewed_cont_columns = []\nfor i, cn in enumerate(cont_columns):\n    if skewness_list[i] >= 0.25:\n        skewed_cont_columns.append(cn)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(15,25))\ngs = gridspec.GridSpec(6, 2)\nfor i, cn in enumerate(skewed_cont_columns):\n    ax = plt.subplot(gs[i])\n    sns.distplot(train[cn], bins=50)\n    ax.set_xlabel('')\n    ax.set_title('hist plot of feature: ' + str(cn))\nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Below function comes in handy in plotting the distribution and probability plot side by side and we look at \n\n - original feature\n - custom transformed feature\n - boxcox transformed feature\n\nin some cases custom transformation might be better than boxcox transformation, let's analyze.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def examine_transform(original, transformed):\n    plt.figure(figsize=(15,10))\n    gs = gridspec.GridSpec(3,2, width_ratios=(1,2))\n    \n    ax = plt.subplot(gs[0])\n    sns.distplot(original, bins=50)\n    ax.set_xlabel('')\n    ax.set_title('histogram of orignal feature')\n    \n    ax = plt.subplot(gs[1])\n    prob = stats.probplot(original, dist = stats.norm, plot = ax)\n    ax.set_xlabel('')\n    ax.set_title('Probplot of original feature')\n    \n    ax = plt.subplot(gs[2])\n    sns.distplot(transformed, bins=50)\n    ax.set_xlabel('')\n    ax.set_title('histogram of transformed feature')\n    \n    ax = plt.subplot(gs[3])\n    prob = stats.probplot(transformed, dist = stats.norm, plot = ax)\n    ax.set_xlabel('')\n    ax.set_title('Probplot of transformed feature')\n    \n    # apply boxcox transformation\n    xt, _ = stats.boxcox(original)\n    ax = plt.subplot(gs[4])\n    sns.distplot(xt, bins=50)\n    ax.set_xlabel('')\n    ax.set_title('histogram of boxcox transformed feature')\n    \n    ax = plt.subplot(gs[5])\n    prob = stats.probplot(xt, dist = stats.norm, plot = ax)\n    ax.set_xlabel('')\n    ax.set_title('Probplot of boxcox transformed feature')\n    \n    \n    plt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont1, np.power(train.cont1,0.5))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont2, np.tan(train.cont2))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont4, np.power(train.cont4,0.2))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont5, np.log(train.cont5))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont6, np.power(train.cont6,0.5))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont7, np.log(train.cont7))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont8, np.power(train.cont8,0.4))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont9, np.power(train.cont9,0.4))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont10+1, np.tanh(train.cont10+1))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont11, np.power(train.cont11,0.4))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont12, np.power(train.cont12,0.4))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont13, np.abs(train.cont13 - np.mean(train.cont13)))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "examine_transform(train.cont14, np.abs(train.cont14 - np.mean(train.cont14)))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# here is the pick of the transformation based on the above analysis\nfeature_transformation = {  'cont1': 'boxcox'\n                          , 'cont2': 'np.tan'\n                          , 'cont3': 'none'\n                          , 'cont4': 'boxcox'\n                          , 'cont5': 'boxcox'\n                          , 'cont6': 'boxcox'\n                          , 'cont7': 'boxcox'\n                          , 'cont8': 'boxcox'\n                          , 'cont9': 'boxcox'\n                          , 'cont10': 'boxcox'\n                          , 'cont11': 'boxcox'\n                          , 'cont12': 'boxcox'\n                          , 'cont13': 'abs_mean_shift'\n                          , 'cont14': 'abs_mean_shift'\n                         }",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}